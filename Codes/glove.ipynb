{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm == 0:\n",
    "        return vector\n",
    "    return vector / norm\n",
    "\n",
    "def calculate_query_vector(tfidf_matrix, query):\n",
    "    # Tokenize and preprocess the query\n",
    "    query_tokens = query.split()\n",
    "    \n",
    "    # Initialize query vector\n",
    "    query_vector = np.zeros(tfidf_matrix.shape[1])\n",
    "    \n",
    "    # Calculate TF-IDF weights for the query\n",
    "    for token in query_tokens:\n",
    "        if token in vocabulary:\n",
    "            token_index = vocabulary.index(token)\n",
    "            query_vector[token_index] = tfidf_matrix[:, token_index].max()\n",
    "    \n",
    "    # Normalize the query vector\n",
    "    normalized_query_vector = normalize_vector(query_vector)\n",
    "    \n",
    "    return normalized_query_vector\n",
    "\n",
    "# Example TF-IDF matrix (replace with your own)\n",
    "tfidf_matrix = np.array([\n",
    "    [0.2, 0.4, 0.6, 0.0],\n",
    "    [0.1, 0.3, 0.0, 0.5],\n",
    "    [0.3, 0.0, 0.5, 0.2]\n",
    "])\n",
    "\n",
    "# Example vocabulary (replace with your own)\n",
    "vocabulary = [\"term1\", \"term2\", \"term3\", \"term4\"]\n",
    "\n",
    "# Example query (replace with your own)\n",
    "query = \"term1 term3 term5\"\n",
    "\n",
    "# Calculate normalized query vector\n",
    "normalized_query_vector = calculate_query_vector(tfidf_matrix, query)\n",
    "print(\"Normalized Query Vector:\", normalized_query_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOVE EMBEDDINGS\n",
    "    Download the pre-trained model from https://github.com/stanfordnlp/GloVe?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/bones/Downloads/glove.6B/glove.6B.100d.txt\" #github download\n",
    "\n",
    "\n",
    "def is_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def process_text_file(file_path):\n",
    "    final_dict = {}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        current_key = None\n",
    "        current_values = []\n",
    "\n",
    "        for line in file:\n",
    "            elements = line.split()\n",
    "            for elem in elements:\n",
    "                if elem[0].isalpha():\n",
    "                    if current_key is not None and current_values:\n",
    "                        final_dict[current_key] = current_values\n",
    "                    current_key = elem\n",
    "                    current_values = []\n",
    "                elif is_float(elem):\n",
    "                    current_values.append(float(elem))\n",
    "        \n",
    "        if current_key is not None and current_values:\n",
    "            final_dict[current_key] = current_values\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "# Example\n",
    "result = process_text_file(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def process_text_file(file_path, output_file_path):\n",
    "    current_key = None\n",
    "    current_values = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            for line in file:\n",
    "                elements = line.split()\n",
    "                for elem in elements:\n",
    "                    if elem[0].isalpha():\n",
    "                        if current_key is not None and current_values:\n",
    "                            output_file.write(f\"{current_key} {' '.join(map(str, current_values))}\\n\")\n",
    "                        current_key = elem\n",
    "                        current_values = []\n",
    "                    elif is_float(elem):\n",
    "                        current_values.append(float(elem))\n",
    "        \n",
    "            # Write the last key-value pair to the output file\n",
    "            if current_key is not None and current_values:\n",
    "                output_file.write(f\"{current_key} {' '.join(map(str, current_values))}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_file_path = \"C:/Users/bones/Downloads/glove.6B/glove.6B.100d.txt\" #\"C:\\Users\\bones\\Downloads\\glove.6B\\example.txt\"\n",
    "output_directory = \"C:/Users/bones/Downloads/glove.6B/glove.6B.100d_output.txt\"  # Specify the directory where output files will be saved\n",
    "process_text_file(input_file_path, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "input_file_path = \"C:/Users/bones/Downloads/glove.6B/example.txt\" #\"C:\\Users\\bones\\Downloads\\glove.6B\\example.txt\"\n",
    "output_directory = \"C:/Users/bones/Downloads/glove.6B/glove.6B.100d_output.txt\"  # Specify the directory where output files will be saved\n",
    "process_text_file(input_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the word at 39914 and the vector is ['aeroplane', '-0.11011', '-0.041525', '0.019518', '0.78615', '-0.72569', '-0.39956', '0.59432', '0.12629', '0.092823', '0.6423', '0.69498', '-0.62381', '-0.13936', '0.087131', '0.019182', '-0.27002', '0.73525', '0.076906', '0.90505', '-0.048114', '0.53708', '-0.55477', '-0.31204', '-0.79876', '0.57272', '0.65268', '-0.53473', '0.15448', '-0.23826', '-0.1262', '-0.88732', '0.076586', '0.10477', '0.22381', '-0.72573', '0.72373', '-0.052784', '0.42793', '0.20138', '-0.17998', '-0.12104', '0.58001', '-0.64999', '-0.2695', '0.44954', '-0.057432', '0.25556', '0.20647', '0.47835', '-0.27637', '-0.53805', '0.58715', '0.029126', '0.58192', '0.34265', '0.49561', '-0.14611', '0.4378', '0.57515', '-0.2222', '0.81166', '0.068907', '-0.0051384', '1.1106', '-0.11483', '-0.40277', '-0.6258', '-0.26688', '-0.79309', '0.21467', '-0.95724', '-0.30291', '0.35433', '-0.60151', '-0.11591', '-0.041187', '0.19937', '-0.18353', '-0.85402', '-0.16026', '-0.50172', '0.080392', '0.33302', '1.2458', '0.18392', '-0.80336', '0.18759', '-0.78739', '-0.22876', '-0.36431', '-0.71418', '-0.17044', '0.078473', '0.14082', '0.4786', '0.076541', '-0.85553', '-0.1778', '0.53968', '-0.66335']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "def vector_retrieval(word):\n",
    "    with open(\"C:/Users/bones/Downloads/glove.6B/glove.6B.100d_output.txt\",'r') as o_file:\n",
    "        for line_idx,line in enumerate(o_file):\n",
    "            substrings = line.split()\n",
    "            if isinstance(word,str) and substrings[0] == word:\n",
    "                print(f\"Found the word at {line_idx} and the vector is {[(s) for s in substrings[:]]}\")\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "vector_retrieval('aeroplane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
